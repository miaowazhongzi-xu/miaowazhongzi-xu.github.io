(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{1119:function(s,r,a){s.exports=a.p+"assets/img/7.4.2.scrapy_redis的流程.245daeb2.png"},1327:function(s,r,a){"use strict";a.r(r);var t=a(3),_=Object(t.a)({},(function(){var s=this,r=s.$createElement,t=s._self._c||r;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"scrapy-redis概念作用和流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-redis概念作用和流程"}},[s._v("#")]),s._v(" scrapy_redis概念作用和流程")]),s._v(" "),t("h5",{attrs:{id:"学习目标"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标")]),s._v(" "),t("ol",[t("li",[s._v("了解 分布式的概念及特点")]),s._v(" "),t("li",[s._v("了解 scarpy_redis的概念")]),s._v(" "),t("li",[s._v("了解 scrapy_redis的作用")]),s._v(" "),t("li",[s._v("了解 scrapy_redis的工作流程")])]),s._v(" "),t("hr"),s._v(" "),t("blockquote",[t("p",[s._v("在前面scrapy框架中我们已经能够使用框架实现爬虫爬取网站数据,如果当前网站的数据比较庞大, 我们就需要使用分布式来更快的爬取数据")])]),s._v(" "),t("h3",{attrs:{id:"_1-分布式是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-分布式是什么"}},[s._v("#")]),s._v(" 1. 分布式是什么")]),s._v(" "),t("blockquote",[t("p",[s._v("简单的说 分布式就是不同的节点（服务器，ip不同）共同完成一个任务")])]),s._v(" "),t("h3",{attrs:{id:"_2-scrapy-redis的概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-scrapy-redis的概念"}},[s._v("#")]),s._v(" 2. scrapy_redis的概念")]),s._v(" "),t("p",[s._v("scrapy_redis是scrapy框架的基于redis的分布式组件")]),s._v(" "),t("h3",{attrs:{id:"_3-scrapy-redis的作用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-scrapy-redis的作用"}},[s._v("#")]),s._v(" 3. scrapy_redis的作用")]),s._v(" "),t("blockquote",[t("p",[s._v("Scrapy_redis在scrapy的基础上实现了更多，更强大的功能，具体体现在：")])]),s._v(" "),t("p",[s._v("通过持久化请求队列和请求的指纹集合来实现：")]),s._v(" "),t("ul",[t("li",[s._v("断点续爬")]),s._v(" "),t("li",[s._v("分布式快速抓取")])]),s._v(" "),t("h3",{attrs:{id:"_4-scrapy-redis的工作流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-scrapy-redis的工作流程"}},[s._v("#")]),s._v(" 4. scrapy_redis的工作流程")]),s._v(" "),t("h4",{attrs:{id:"_4-1-回顾scrapy的流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-回顾scrapy的流程"}},[s._v("#")]),s._v(" 4.1 回顾scrapy的流程")]),s._v(" "),t("img",{attrs:{src:a(788),width:"140%"}}),s._v(" "),t("h5",{attrs:{id:"思考-那么-在这个基础上-如果需要实现分布式-即多台服务器同时完成一个爬虫-需要怎么做呢"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#思考-那么-在这个基础上-如果需要实现分布式-即多台服务器同时完成一个爬虫-需要怎么做呢"}},[s._v("#")]),s._v(" 思考：那么，在这个基础上，如果需要实现分布式，即多台服务器同时完成一个爬虫，需要怎么做呢？")]),s._v(" "),t("h4",{attrs:{id:"_4-2-scrapy-redis的流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-scrapy-redis的流程"}},[s._v("#")]),s._v(" 4.2 scrapy_redis的流程")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("在scrapy_redis中，所有的待抓取的request对象和去重的request对象指纹都存在所有的服务器公用的redis中")])]),s._v(" "),t("li",[t("p",[s._v("所有的服务器中的scrapy进程公用同一个redis中的request对象的队列")])]),s._v(" "),t("li",[t("p",[s._v("所有的request对象存入redis前，都会通过该redis中的request指纹集合进行判断，之前是否已经存入过")])]),s._v(" "),t("li",[t("p",[s._v("在默认情况下所有的数据会保存在redis中")])])]),s._v(" "),t("p",[s._v("具体流程如下：")]),s._v(" "),t("img",{attrs:{src:a(1119),width:"140%"}}),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),t("p",[s._v("scarpy_redis的分布式工作原理")]),s._v(" "),t("ul",[t("li",[s._v("在scrapy_redis中，所有的待抓取的对象和去重的指纹都存在公用的redis中")]),s._v(" "),t("li",[s._v("所有的服务器公用同一redis中的请求对象的队列")]),s._v(" "),t("li",[s._v("所有的request对象存入redis前，都会通过请求对象的指纹进行判断，之前是否已经存入过")])]),s._v(" "),t("hr")])}),[],!1,null,null,null);r.default=_.exports},788:function(s,r,a){s.exports=a.p+"assets/img/1.3.3.scrapy工作流程.19eaffd9.png"}}]);