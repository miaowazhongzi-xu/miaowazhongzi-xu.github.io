(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{1106:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-1.c5a40a99.jpg"},1107:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-2.937d9908.jpg"},1108:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-3.6d493b0d.jpg"},1109:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-4.d933f02e.jpg"},1110:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-5.ea91015a.jpg"},1111:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-6.45d8ed17.jpg"},1112:function(s,a,t){s.exports=t.p+"assets/img/11.scrapyd-7.47c18e28.jpg"},1321:function(s,a,t){"use strict";t.r(a);var r=t(3),e=Object(r.a)({},(function(){var s=this,a=s.$createElement,r=s._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[r("h2",{attrs:{id:"scrapyd部署scrapy项目"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#scrapyd部署scrapy项目"}},[s._v("#")]),s._v(" scrapyd部署scrapy项目")]),s._v(" "),r("h5",{attrs:{id:"学习目标"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标")]),s._v(" "),r("ol",[r("li",[s._v("了解 scrapyd的使用流程")])]),s._v(" "),r("hr"),s._v(" "),r("h3",{attrs:{id:"_1-scrapyd的介绍"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-scrapyd的介绍"}},[s._v("#")]),s._v(" 1. scrapyd的介绍")]),s._v(" "),r("p",[s._v("scrapyd是一个用于部署和运行scrapy爬虫的程序，它允许你通过JSON API来"),r("strong",[s._v("部署爬虫项目和控制爬虫运行")]),s._v("，scrapyd是一个守护进程，监听爬虫的运行和请求，然后启动进程来执行它们")]),s._v(" "),r("blockquote",[r("p",[s._v("所谓json api本质就是post请求的webapi")])]),s._v(" "),r("h3",{attrs:{id:"_2-scrapyd的安装"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-scrapyd的安装"}},[s._v("#")]),s._v(" 2. scrapyd的安装")]),s._v(" "),r("p",[s._v("scrapyd服务:\n"),r("code",[s._v("pip install scrapyd")])]),s._v(" "),r("p",[s._v("scrapyd客户端:\n"),r("code",[s._v("pip install scrapyd-client")])]),s._v(" "),r("h3",{attrs:{id:"_3-启动scrapyd服务"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-启动scrapyd服务"}},[s._v("#")]),s._v(" 3. 启动scrapyd服务")]),s._v(" "),r("ol",[r("li",[r("p",[r("strong",[s._v("在scrapy项目路径下")]),s._v(" 启动scrapyd的命令："),r("code",[s._v("sudo scrapyd")]),s._v(" 或 "),r("code",[s._v("scrapyd")])])]),s._v(" "),r("li",[r("p",[s._v("启动之后就可以打开本地运行的scrapyd，浏览器中访问本地6800端口可以查看scrapyd的监控界面")])])]),s._v(" "),r("img",{attrs:{src:t(1106),width:"100%"}}),s._v(" "),r("img",{attrs:{src:t(1107),width:"100%"}}),s._v(" "),r("ul",[r("li",[s._v("点击job可以查看任务监控界面")])]),s._v(" "),r("img",{attrs:{src:t(1108),width:"100%"}}),s._v(" "),r("h3",{attrs:{id:"_4-scrapy项目部署"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-scrapy项目部署"}},[s._v("#")]),s._v(" 4. scrapy项目部署")]),s._v(" "),r("h4",{attrs:{id:"_4-1-配置需要部署的项目"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-配置需要部署的项目"}},[s._v("#")]),s._v(" 4.1 配置需要部署的项目")]),s._v(" "),r("p",[s._v("编辑需要部署的项目的scrapy.cfg文件(需要将哪一个爬虫部署到scrapyd中，就配置该项目的该文件)")]),s._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[s._v("[deploy:部署名(部署名可以自行定义)]\nurl = http://localhost:6800/\nproject = 项目名(创建爬虫项目时使用的名称)\n")])]),s._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[s._v("1")]),r("br"),r("span",{staticClass:"line-number"},[s._v("2")]),r("br"),r("span",{staticClass:"line-number"},[s._v("3")]),r("br")])]),r("img",{attrs:{src:t(1109),width:"100%"}}),s._v(" "),r("h4",{attrs:{id:"_4-2-部署项目到scrapyd"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-部署项目到scrapyd"}},[s._v("#")]),s._v(" 4.2 部署项目到scrapyd")]),s._v(" "),r("p",[s._v("同样在"),r("strong",[s._v("scrapy项目路径下")]),s._v("执行：")]),s._v(" "),r("p",[r("code",[s._v("scrapyd-deploy 部署名(配置文件中设置的名称) -p 项目名称")])]),s._v(" "),r("img",{attrs:{src:t(1110),width:"100%"}}),s._v(" "),r("p",[s._v("部署成功之后就可以看到部署的项目\n"),r("img",{attrs:{src:t(1111),width:"100%"}})]),s._v(" "),r("h4",{attrs:{id:"_4-3-管理scrapy项目"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-管理scrapy项目"}},[s._v("#")]),s._v(" 4.3 管理scrapy项目")]),s._v(" "),r("ul",[r("li",[s._v("启动项目："),r("code",[s._v("curl http://localhost:6800/schedule.json -d project=project_name -d spider=spider_name")])])]),s._v(" "),r("img",{attrs:{src:t(1112),width:"100%"}}),s._v(" "),r("ul",[r("li",[s._v("关闭爬虫："),r("code",[s._v("curl http://localhost:6800/cancel.json -d project=project_name -d job=jobid")])])]),s._v(" "),r("h5",{attrs:{id:"注意-curl是命令行工具-如果没有则需要额外安装"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#注意-curl是命令行工具-如果没有则需要额外安装"}},[s._v("#")]),s._v(" 注意；curl是命令行工具，如果没有则需要额外安装")]),s._v(" "),r("h4",{attrs:{id:"_4-4-使用requests模块控制scrapy项目"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-使用requests模块控制scrapy项目"}},[s._v("#")]),s._v(" 4.4 使用requests模块控制scrapy项目")]),s._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[s._v("import requests\n\n# 启动爬虫\nurl = 'http://localhost:6800/schedule.json'\ndata = {\n\t'project': 项目名,\n\t'spider': 爬虫名,\n}\nresp = requests.post(url, data=data)\n\n# 停止爬虫\nurl = 'http://localhost:6800/cancel.json'\ndata = {\n\t'project': 项目名,\n\t'job': 启动爬虫时返回的jobid,\n}\nresp = requests.post(url, data=data)\n")])]),s._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[s._v("1")]),r("br"),r("span",{staticClass:"line-number"},[s._v("2")]),r("br"),r("span",{staticClass:"line-number"},[s._v("3")]),r("br"),r("span",{staticClass:"line-number"},[s._v("4")]),r("br"),r("span",{staticClass:"line-number"},[s._v("5")]),r("br"),r("span",{staticClass:"line-number"},[s._v("6")]),r("br"),r("span",{staticClass:"line-number"},[s._v("7")]),r("br"),r("span",{staticClass:"line-number"},[s._v("8")]),r("br"),r("span",{staticClass:"line-number"},[s._v("9")]),r("br"),r("span",{staticClass:"line-number"},[s._v("10")]),r("br"),r("span",{staticClass:"line-number"},[s._v("11")]),r("br"),r("span",{staticClass:"line-number"},[s._v("12")]),r("br"),r("span",{staticClass:"line-number"},[s._v("13")]),r("br"),r("span",{staticClass:"line-number"},[s._v("14")]),r("br"),r("span",{staticClass:"line-number"},[s._v("15")]),r("br"),r("span",{staticClass:"line-number"},[s._v("16")]),r("br"),r("span",{staticClass:"line-number"},[s._v("17")]),r("br")])]),r("h3",{attrs:{id:"_5-了解scrapyd的其他webapi"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-了解scrapyd的其他webapi"}},[s._v("#")]),s._v(" 5. 了解scrapyd的其他webapi")]),s._v(" "),r("ul",[r("li",[s._v("curl http://localhost:6800/listprojects.json    （列出项目）")]),s._v(" "),r("li",[s._v("curl http://localhost:6800/listspiders.json?project=myspider   （列出爬虫）")]),s._v(" "),r("li",[s._v("curl http://localhost:6800/listjobs.json?project=myspider    （列出job）")]),s._v(" "),r("li",[s._v("curl http://localhost:6800/cancel.json -d project=myspider -d job=tencent    （"),r("strong",[s._v("终止爬虫")]),s._v("，该功能会有延时或不能终止爬虫的情况，此时可用kill -9杀进程的方式中止）")]),s._v(" "),r("li",[s._v("scrapyd还有其他webapi，百度搜索了解更多")])]),s._v(" "),r("hr"),s._v(" "),r("h3",{attrs:{id:"小结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),r("ol",[r("li",[s._v("在scrapy项目路径下执行"),r("code",[s._v("sudo scrapyd")]),s._v("或"),r("code",[s._v("scrapyd")]),s._v("，启动scrapyd服务；或以后台进程方式启动"),r("code",[s._v("nohup scrapyd > scrapyd.log 2>&1 &")])]),s._v(" "),r("li",[s._v("部署scrapy爬虫项目"),r("code",[s._v("scrapyd-deploy -p myspider")])]),s._v(" "),r("li",[s._v("启动爬虫项目中的一个爬虫"),r("code",[s._v("curl http://localhost:6800/schedule.json -d project=myspider -d spider=tencent")])])]),s._v(" "),r("hr")])}),[],!1,null,null,null);a.default=e.exports}}]);