(window.webpackJsonp=window.webpackJsonp||[]).push([[72],{1328:function(s,e,i){"use strict";i.r(e);var n=i(3),t=Object(n.a)({},(function(){var s=this,e=s.$createElement,i=s._self._c||e;return i("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[i("h2",{attrs:{id:"scrapy管道的使用"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#scrapy管道的使用"}},[s._v("#")]),s._v(" scrapy管道的使用")]),s._v(" "),i("h5",{attrs:{id:"学习目标"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标：")]),s._v(" "),i("ol",[i("li",[s._v("掌握 scrapy管道(pipelines.py)的使用")])]),s._v(" "),i("hr"),s._v(" "),i("blockquote",[i("p",[s._v("之前我们在scrapy入门使用一节中学习了管道的基本使用，接下来我们深入的学习scrapy管道的使用")])]),s._v(" "),i("h3",{attrs:{id:"_1-pipeline中常用的方法"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_1-pipeline中常用的方法"}},[s._v("#")]),s._v(" 1. pipeline中常用的方法：")]),s._v(" "),i("ol",[i("li",[s._v("process_item(self,item,spider):\n"),i("ul",[i("li",[s._v("管道类中必须有的函数")]),s._v(" "),i("li",[s._v("实现对item数据的处理")]),s._v(" "),i("li",[s._v("必须return item")])])]),s._v(" "),i("li",[s._v("open_spider(self, spider): 在爬虫开启的时候仅执行一次")]),s._v(" "),i("li",[s._v("close_spider(self, spider): 在爬虫关闭的时候仅执行一次")])]),s._v(" "),i("h3",{attrs:{id:"_2-管道文件的修改"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-管道文件的修改"}},[s._v("#")]),s._v(" 2. 管道文件的修改")]),s._v(" "),i("blockquote",[i("p",[s._v("继续完善wangyi爬虫，在pipelines.py代码中完善")])]),s._v(" "),i("div",{staticClass:"language- line-numbers-mode"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[s._v("import json\nfrom pymongo import MongoClient\n\nclass WangyiFilePipeline(object):\n    def open_spider(self, spider):  # 在爬虫开启的时候仅执行一次\n        if spider.name == 'itcast':\n            self.f = open('json.txt', 'a', encoding='utf-8')\n\n    def close_spider(self, spider):  # 在爬虫关闭的时候仅执行一次\n        if spider.name == 'itcast':\n            self.f.close()\n\n    def process_item(self, item, spider):\n        if spider.name == 'itcast':\n            self.f.write(json.dumps(dict(item), ensure_ascii=False, indent=2) + ',\\n')\n        # 不return的情况下，另一个权重较低的pipeline将不会获得item\n        return item  \n\nclass WangyiMongoPipeline(object):\n    def open_spider(self, spider):  # 在爬虫开启的时候仅执行一次\n        if spider.name == 'itcast':\n        # 也可以使用isinstanc函数来区分爬虫类:\n            con = MongoClient(host='127.0.0.1', port=27017) # 实例化mongoclient\n            self.collection = con.itcast.teachers # 创建数据库名为itcast,集合名为teachers的集合操作对象\n\n    def process_item(self, item, spider):\n        if spider.name == 'itcast':\n            self.collection.insert(item) \n            # 此时item对象必须是一个字典,再插入\n            # 如果此时item是BaseItem则需要先转换为字典：dict(BaseItem)\n        # 不return的情况下，另一个权重较低的pipeline将不会获得item\n        return item  \n")])]),s._v(" "),i("div",{staticClass:"line-numbers-wrapper"},[i("span",{staticClass:"line-number"},[s._v("1")]),i("br"),i("span",{staticClass:"line-number"},[s._v("2")]),i("br"),i("span",{staticClass:"line-number"},[s._v("3")]),i("br"),i("span",{staticClass:"line-number"},[s._v("4")]),i("br"),i("span",{staticClass:"line-number"},[s._v("5")]),i("br"),i("span",{staticClass:"line-number"},[s._v("6")]),i("br"),i("span",{staticClass:"line-number"},[s._v("7")]),i("br"),i("span",{staticClass:"line-number"},[s._v("8")]),i("br"),i("span",{staticClass:"line-number"},[s._v("9")]),i("br"),i("span",{staticClass:"line-number"},[s._v("10")]),i("br"),i("span",{staticClass:"line-number"},[s._v("11")]),i("br"),i("span",{staticClass:"line-number"},[s._v("12")]),i("br"),i("span",{staticClass:"line-number"},[s._v("13")]),i("br"),i("span",{staticClass:"line-number"},[s._v("14")]),i("br"),i("span",{staticClass:"line-number"},[s._v("15")]),i("br"),i("span",{staticClass:"line-number"},[s._v("16")]),i("br"),i("span",{staticClass:"line-number"},[s._v("17")]),i("br"),i("span",{staticClass:"line-number"},[s._v("18")]),i("br"),i("span",{staticClass:"line-number"},[s._v("19")]),i("br"),i("span",{staticClass:"line-number"},[s._v("20")]),i("br"),i("span",{staticClass:"line-number"},[s._v("21")]),i("br"),i("span",{staticClass:"line-number"},[s._v("22")]),i("br"),i("span",{staticClass:"line-number"},[s._v("23")]),i("br"),i("span",{staticClass:"line-number"},[s._v("24")]),i("br"),i("span",{staticClass:"line-number"},[s._v("25")]),i("br"),i("span",{staticClass:"line-number"},[s._v("26")]),i("br"),i("span",{staticClass:"line-number"},[s._v("27")]),i("br"),i("span",{staticClass:"line-number"},[s._v("28")]),i("br"),i("span",{staticClass:"line-number"},[s._v("29")]),i("br"),i("span",{staticClass:"line-number"},[s._v("30")]),i("br"),i("span",{staticClass:"line-number"},[s._v("31")]),i("br"),i("span",{staticClass:"line-number"},[s._v("32")]),i("br")])]),i("h3",{attrs:{id:"_3-开启管道"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_3-开启管道"}},[s._v("#")]),s._v(" 3. 开启管道")]),s._v(" "),i("p",[s._v("在settings.py设置开启pipeline")]),s._v(" "),i("div",{staticClass:"language- line-numbers-mode"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[s._v("......\nITEM_PIPELINES = {\n    'myspider.pipelines.ItcastFilePipeline': 400, # 400表示权重\n    'myspider.pipelines.ItcastMongoPipeline': 500, # 权重值越小，越优先执行！\n}\n......\n")])]),s._v(" "),i("div",{staticClass:"line-numbers-wrapper"},[i("span",{staticClass:"line-number"},[s._v("1")]),i("br"),i("span",{staticClass:"line-number"},[s._v("2")]),i("br"),i("span",{staticClass:"line-number"},[s._v("3")]),i("br"),i("span",{staticClass:"line-number"},[s._v("4")]),i("br"),i("span",{staticClass:"line-number"},[s._v("5")]),i("br"),i("span",{staticClass:"line-number"},[s._v("6")]),i("br")])]),i("p",[i("strong",[s._v("别忘了开启mongodb数据库 "),i("code",[s._v("sudo service mongodb start")])]),s._v(" "),i("strong",[s._v("并在mongodb数据库中查看 "),i("code",[s._v("mongo")])])]),s._v(" "),i("p",[i("strong",[s._v("思考：在settings中能够开启多个管道，为什么需要开启多个？")])]),s._v(" "),i("ol",[i("li",[s._v("不同的pipeline可以处理不同爬虫的数据，通过spider.name属性来区分")]),s._v(" "),i("li",[s._v("不同的pipeline能够对一个或多个爬虫进行不同的数据处理的操作，比如一个进行数据清洗，一个进行数据的保存")]),s._v(" "),i("li",[s._v("同一个管道类也可以处理不同爬虫的数据，通过spider.name属性来区分")])]),s._v(" "),i("h3",{attrs:{id:"_4-pipeline使用注意点"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_4-pipeline使用注意点"}},[s._v("#")]),s._v(" 4. pipeline使用注意点")]),s._v(" "),i("ol",[i("li",[s._v("使用之前需要在settings中开启")]),s._v(" "),i("li",[s._v("pipeline在setting中键表示位置(即pipeline在项目中的位置可以自定义)，值表示距离引擎的远近，越近数据会越先经过："),i("strong",[s._v("权重值小的优先执行")])]),s._v(" "),i("li",[s._v("有多个pipeline的时候，process_item的方法必须return item,否则后一个pipeline取到的数据为None值")]),s._v(" "),i("li",[s._v("pipeline中process_item的方法必须有，否则item没有办法接受和处理")]),s._v(" "),i("li",[s._v("process_item方法接受item和spider，其中spider表示当前传递item过来的spider")]),s._v(" "),i("li",[s._v("open_spider(spider) :能够在爬虫开启的时候执行一次")]),s._v(" "),i("li",[s._v("close_spider(spider) :能够在爬虫关闭的时候执行一次")]),s._v(" "),i("li",[s._v("上述俩个方法经常用于爬虫和数据库的交互，在爬虫开启的时候建立和数据库的连接，在爬虫关闭的时候断开和数据库的连接")])]),s._v(" "),i("hr"),s._v(" "),i("h2",{attrs:{id:"小结"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),i("ul",[i("li",[s._v("管道能够实现数据的清洗和保存，能够定义多个管道实现不同的功能，其中有个三个方法\n"),i("ul",[i("li",[s._v("process_item(self,item,spider):实现对item数据的处理")]),s._v(" "),i("li",[s._v("open_spider(self, spider):  在爬虫开启的时候仅执行一次")]),s._v(" "),i("li",[s._v("close_spider(self, spider):  在爬虫关闭的时候仅执行一次")])])])]),s._v(" "),i("hr")])}),[],!1,null,null,null);e.default=t.exports}}]);