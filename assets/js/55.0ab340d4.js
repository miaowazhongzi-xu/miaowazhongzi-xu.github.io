(window.webpackJsonp=window.webpackJsonp||[]).push([[55],{1113:function(s,t,a){s.exports=a.p+"assets/img/3.1.scrapy.d600af54.png"},1322:function(s,t,a){"use strict";a.r(t);var n=a(3),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("h2",{attrs:{id:"scrapy数据建模与请求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#scrapy数据建模与请求"}},[s._v("#")]),s._v(" scrapy数据建模与请求")]),s._v(" "),n("h5",{attrs:{id:"学习目标"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标：")]),s._v(" "),n("ol",[n("li",[s._v("应用 在scrapy项目中进行建模")]),s._v(" "),n("li",[s._v("应用 构造Request对象，并发送请求")]),s._v(" "),n("li",[s._v("应用 利用meta参数在不同的解析函数中传递数据")])]),s._v(" "),n("hr"),s._v(" "),n("h3",{attrs:{id:"_1-数据建模"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-数据建模"}},[s._v("#")]),s._v(" 1. 数据建模")]),s._v(" "),n("blockquote",[n("p",[s._v("通常在做项目的过程中，在items.py中进行数据建模")])]),s._v(" "),n("h4",{attrs:{id:"_1-1-为什么建模"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-为什么建模"}},[s._v("#")]),s._v(" 1.1 为什么建模")]),s._v(" "),n("ol",[n("li",[s._v("定义item即提前规划好哪些字段需要抓，防止手误，因为定义好之后，在运行过程中，系统会自动检查")]),s._v(" "),n("li",[s._v("配合注释一起可以清晰的知道要抓取哪些字段，没有定义的字段不能抓取，在目标字段少的时候可以使用字典代替")]),s._v(" "),n("li",[s._v("使用scrapy的一些特定组件需要Item做支持，如scrapy的ImagesPipeline管道类，百度搜索了解更多")])]),s._v(" "),n("h4",{attrs:{id:"_1-2-如何建模"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-如何建模"}},[s._v("#")]),s._v(" 1.2 如何建模")]),s._v(" "),n("p",[s._v("在items.py文件中定义要提取的字段：")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("class MyspiderItem(scrapy.Item): \n    name = scrapy.Field()   # 讲师的名字\n    title = scrapy.Field()  # 讲师的职称\n    desc = scrapy.Field()   # 讲师的介绍\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("h4",{attrs:{id:"_1-3-如何使用模板类"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-如何使用模板类"}},[s._v("#")]),s._v(" 1.3 如何使用模板类")]),s._v(" "),n("p",[s._v("模板类定义以后需要在爬虫中导入并且实例化，之后的使用方法和使用字典相同")]),s._v(" "),n("p",[s._v("job.py：")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("from myspider.items import MyspiderItem   # 导入Item，注意路径\n...\n    def parse(self, response)\n\n        item = MyspiderItem() # 实例化后可直接使用\n\n        item['name'] = node.xpath('./h3/text()').extract_first()\n        item['title'] = node.xpath('./h4/text()').extract_first()\n        item['desc'] = node.xpath('./p/text()').extract_first()\n        \n        print(item)\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br")])]),n("p",[s._v("注意：")]),s._v(" "),n("ol",[n("li",[s._v("from myspider.items import MyspiderItem这一行代码中 注意item的正确导入路径，忽略pycharm标记的错误")]),s._v(" "),n("li",[s._v("python中的导入路径要诀：从哪里开始运行，就从哪里开始导入")])]),s._v(" "),n("h4",{attrs:{id:"_1-4-开发流程总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-开发流程总结"}},[s._v("#")]),s._v(" 1.4 开发流程总结")]),s._v(" "),n("ol",[n("li",[s._v("创建项目"),n("br"),s._v("\nscrapy startproject 项目名"),n("br")]),s._v(" "),n("li",[s._v("明确目标"),n("br"),s._v("\n在items.py文件中进行建模")]),s._v(" "),n("li",[s._v("创建爬虫"),n("br"),s._v("\n3.1 创建爬虫"),n("br"),s._v("\nscrapy genspider 爬虫名 允许的域\n3.2 完成爬虫"),n("br"),s._v("\n修改start_urls\n检查修改allowed_domains\n编写解析方法")]),s._v(" "),n("li",[s._v("保存数据"),n("br"),s._v("\n在pipelines.py文件中定义对数据处理的管道"),n("br"),s._v("\n在settings.py文件中注册启用管道")])]),s._v(" "),n("h3",{attrs:{id:"_2-翻页请求的思路"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-翻页请求的思路"}},[s._v("#")]),s._v(" 2. 翻页请求的思路")]),s._v(" "),n("blockquote",[n("p",[s._v("对于要提取如下图中所有页面上的数据该怎么办？")])]),s._v(" "),n("img",{attrs:{src:a(1113),width:"100%"}}),s._v(" "),n("p",[s._v("回顾requests模块是如何实现翻页请求的：")]),s._v(" "),n("ol",[n("li",[s._v("找到下一页的URL地址")]),s._v(" "),n("li",[s._v("调用requests.get(url)")])]),s._v(" "),n("p",[s._v("scrapy实现翻页的思路：")]),s._v(" "),n("ol",[n("li",[s._v("找到下一页的url地址")]),s._v(" "),n("li",[s._v("构造url地址的请求对象，传递给引擎")])]),s._v(" "),n("h3",{attrs:{id:"_3-构造request对象-并发送请求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-构造request对象-并发送请求"}},[s._v("#")]),s._v(" 3. 构造Request对象，并发送请求")]),s._v(" "),n("h4",{attrs:{id:"_3-1-实现方法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-实现方法"}},[s._v("#")]),s._v(" 3.1 实现方法")]),s._v(" "),n("ol",[n("li",[s._v("确定url地址")]),s._v(" "),n("li",[s._v("构造请求，scrapy.Request(url,callback)\n"),n("ul",[n("li",[s._v("callback：指定解析函数名称，表示该请求返回的响应使用哪一个函数进行解析")])])]),s._v(" "),n("li",[s._v("把请求交给引擎：yield scrapy.Request(url,callback)")])]),s._v(" "),n("h4",{attrs:{id:"_3-2-网易招聘爬虫"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-网易招聘爬虫"}},[s._v("#")]),s._v(" 3.2 网易招聘爬虫")]),s._v(" "),n("blockquote",[n("p",[s._v("通过爬取网易招聘的页面的招聘信息,学习如何实现翻页请求")])]),s._v(" "),n("blockquote",[n("p",[s._v("地址：https://hr.163.com/position/list.do")])]),s._v(" "),n("h5",{attrs:{id:"思路分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#思路分析"}},[s._v("#")]),s._v(" 思路分析：")]),s._v(" "),n("ol",[n("li",[s._v("获取首页的数据")]),s._v(" "),n("li",[s._v("寻找下一页的地址，进行翻页，获取数据")])]),s._v(" "),n("h5",{attrs:{id:"注意"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[s._v("#")]),s._v(" 注意：")]),s._v(" "),n("ol",[n("li",[s._v("可以在settings中设置ROBOTS协议")])]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("# False表示忽略网站的robots.txt协议，默认为True\nROBOTSTXT_OBEY = False\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("ol",{attrs:{start:"2"}},[n("li",[s._v("可以在settings中设置User-Agent：")])]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("# scrapy发送的每一个请求的默认UA都是设置的这个User-Agent\nUSER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("h4",{attrs:{id:"_3-3-代码实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-代码实现"}},[s._v("#")]),s._v(" 3.3 代码实现")]),s._v(" "),n("p",[s._v("在爬虫文件的parse方法中：")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("\n\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 提取下一页的href")]),s._v("\n\tnext_url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[contains(text(),\">\")]/@href'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 判断是否是最后一页")]),s._v("\n\t"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" next_url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'javascript:void(0)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造完整url")]),s._v("\n        url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://hr.163.com/position/list.do'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" next_url\n\n\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造scrapy.Request对象，并yield给引擎")]),s._v("\n\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 利用callback参数指定该Request对象之后获取的响应用哪个函数进行解析")]),s._v("\n    \t"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callback"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br")])]),n("h4",{attrs:{id:"_3-4-scrapy-request的更多参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-scrapy-request的更多参数"}},[s._v("#")]),s._v(" 3.4 scrapy.Request的更多参数")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("callback"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("method"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"GET"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("headers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("body"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("cookies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("meta"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("dont_filter"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("h5",{attrs:{id:"参数解释"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参数解释"}},[s._v("#")]),s._v(" 参数解释")]),s._v(" "),n("ol",[n("li",[s._v("中括号里的参数为可选参数")]),s._v(" "),n("li",[n("strong",[s._v("callback")]),s._v("：表示当前的url的响应交给哪个函数去处理")]),s._v(" "),n("li",[n("strong",[s._v("meta")]),s._v("：实现数据在不同的解析函数中传递，meta默认带有部分数据，比如下载延迟，请求深度等")]),s._v(" "),n("li",[s._v("dont_filter:默认为False，会过滤请求的url地址，即请求过的url地址不会继续被请求，对需要重复请求的url地址可以把它设置为Ture，比如贴吧的翻页请求，页面的数据总是在变化;start_urls中的地址会被反复请求，否则程序不会启动")]),s._v(" "),n("li",[s._v("method：指定POST或GET请求")]),s._v(" "),n("li",[s._v("headers：接收一个字典，其中不包括cookies")]),s._v(" "),n("li",[s._v("cookies：接收一个字典，专门放置cookies")]),s._v(" "),n("li",[s._v("body：接收json字符串，为POST的数据，发送payload_post请求时使用（在下一章节中会介绍post请求）")])]),s._v(" "),n("h3",{attrs:{id:"_4-meta参数的使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-meta参数的使用"}},[s._v("#")]),s._v(" 4. meta参数的使用")]),s._v(" "),n("blockquote",[n("p",[s._v("meta的作用：meta可以实现数据在不同的解析函数中的传递")])]),s._v(" "),n("p",[s._v("在爬虫文件的parse方法中，提取详情页增加之前callback指定的parse_detail函数：")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v('def parse(self,response):\n    ...\n    yield scrapy.Request(detail_url, callback=self.parse_detail,meta={"item":item})\n...\n\ndef parse_detail(self,response):\n    #获取之前传入的item\n    item = resposne.meta["item"]\n')])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br")])]),n("h5",{attrs:{id:"特别注意"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#特别注意"}},[s._v("#")]),s._v(" 特别注意")]),s._v(" "),n("ol",[n("li",[s._v("meta参数是一个字典")]),s._v(" "),n("li",[s._v("meta字典中有一个固定的键"),n("code",[s._v("proxy")]),s._v("，表示代理ip，关于代理ip的使用我们将在scrapy的下载中间件的学习中进行介绍")])]),s._v(" "),n("hr"),s._v(" "),n("h2",{attrs:{id:"小结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),n("ol",[n("li",[s._v("完善并使用Item数据类：")]),s._v(" "),n("li",[s._v("在items.py中完善要爬取的字段")]),s._v(" "),n("li",[s._v("在爬虫文件中先导入Item")]),s._v(" "),n("li",[s._v("实力化Item对象后，像字典一样直接使用")]),s._v(" "),n("li",[s._v("构造Request对象，并发送请求：")]),s._v(" "),n("li",[s._v("导入scrapy.Request类")]),s._v(" "),n("li",[s._v("在解析函数中提取url")]),s._v(" "),n("li",[s._v("yield scrapy.Request(url, callback=self.parse_detail, meta={})")]),s._v(" "),n("li",[s._v("利用meta参数在不同的解析函数中传递数据:")]),s._v(" "),n("li",[s._v("通过前一个解析函数 yield scrapy.Request(url, callback=self.xxx, meta={}) 来传递meta")]),s._v(" "),n("li",[s._v("在self.xxx函数中 response.meta.get('key', '') 或 response.meta['key'] 的方式取出传递的数据")])]),s._v(" "),n("hr"),s._v(" "),n("h3",{attrs:{id:"参考代码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考代码"}},[s._v("#")]),s._v(" 参考代码")]),s._v(" "),n("p",[s._v("wangyi/spiders/job.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("JobSpider")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'job'")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2.检查允许的域名")]),s._v("\n    allowed_domains "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'163.com'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1 设置起始的url")]),s._v("\n    start_urls "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://hr.163.com/position/list.do'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获取所有的职位节点列表")]),s._v("\n        node_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//*[@class=\"position-tb\"]/tbody/tr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# print(len(node_list))")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 遍历所有的职位节点列表")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" num"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" node "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("enumerate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("node_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 索引为值除2取余为0的才是含有数据的节点，通过判断进行筛选")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" num "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                item "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[1]/a/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'link'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[1]/a/@href'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[2]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'category'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[3]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'type'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[4]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'address'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[5]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'num'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[6]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("strip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'date'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./td[7]/text()'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" item\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 翻页处理")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获取翻页url")]),s._v("\n        part_url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//a[contains(text(),\">\")]/@href'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 判断是否为最后一页，如果不是最后一页则进行翻页操作")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" part_url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'javascript:void(0)'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 拼接完整翻页url")]),s._v("\n            next_url "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://hr.163.com/position/list.do'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" part_url\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                url"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("next_url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                callback"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br")])]),n("p",[s._v("wangyi/items.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("WangyiItem")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# define the fields for your item here like:")]),s._v("\n\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    link "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    depart "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    category "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("type")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    address "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    num "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    date "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scrapy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);